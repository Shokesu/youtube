{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Comments NLP Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "## sklearn\n",
    "import sklearn # machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer # frequency counts matrix\n",
    "from sklearn.model_selection import train_test_split # splitting up data\n",
    "from sklearn import metrics # for accuracy/ precision\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier # Support Vector Machine Classifier\n",
    "# multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in & Clean Data\n",
    "Note that we have to use encoding = \"latin-1\" instead of UTF-8 because we have foreign languages present\n",
    "The different encodings treat characters differently (in latin-1 each character is only one byte long whereas in utf-8 it can me more than one byte in length). Typically utf-8 captures more types of characters, so it was surprising that we had to use latin-8. \n",
    "* for later: look into this more: http://www.unicode.org/reports/tr10/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('/Users/andiedonovan/myProjects/Youtube/') # change directory\n",
    "df = pd.read_csv('labeledCom.csv', delimiter=\";\", skiprows=2, encoding='latin-1', engine='python') # read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                            comment\n",
      "0   -1.0  Everyone knows brand's papers from.\\nBut -No o...\n",
      "1    0.0       ñYour paper cut balance is: \\n-£25279102771î\n",
      "2    1.0  OH SHIT WHEN I SAW THIS ON MY FRONT PAGE.........\n",
      "3    1.0                          Blowing my mind yet again\n",
      "4    0.0               Should have gone with Dunder Mifflin\n"
     ]
    }
   ],
   "source": [
    "# rename the columns\n",
    "df.columns = [\n",
    "  'label',\n",
    "  'comment', \n",
    "  'column3'\n",
    "]\n",
    "df = df.drop('column3', axis = 1).dropna() # drop column 3 and missing values\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training and Test Data\n",
    "Using a pre-defined train-test-split function, we randomly split the data into training data (75%) and test data (25%). We set the x variable for both to the comments, since these are the attributes we will use for classificationand the y variable to the label, as this is what we are trying to predict. The random_state paramteter is simply for reproducability (otherwise the function would produce a different split every time we ran it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                                        df[\"comment\"], df[\"label\"], \n",
    "                                        test_size=0.25, \n",
    "                                       random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure all of the data looks good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths training variables:  820 , 820\n",
      "lengths testing variables:  274 , 274 \n",
      "\n",
      "Are there any missing values? \n",
      " * Training: False , False \n",
      " * Testing:  False , False\n"
     ]
    }
   ],
   "source": [
    "print('lengths training variables: ', len(X_train),\",\", len(Y_train))\n",
    "print('lengths testing variables: ', len(X_test),\",\", len(Y_test), '\\n')\n",
    "\n",
    "print('Are there any missing values?', \n",
    "      '\\n * Training:', pd.isnull(X_train).values.any(), ',', pd.isnull(Y_train).values.any(), \n",
    "      '\\n * Testing: ', pd.isnull(X_test).values.any(), \",\", pd.isnull(Y_test).values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test) # we have a pandas core Series; we just want the comments in an array without numbering\n",
    "# help(X_test) # use values attribute\n",
    "# we will want to use X_test.values(), Y_train.values(), .... to just access the data in list format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Model\n",
    "Documentation: [Scikit-Learn Documentation]('http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#exercise-2-sentiment-analysis-on-movie-reviews')\n",
    "\n",
    "We want to initialize a Count Vectorizer, which will convert the comments to a matrix of token (word) counts. This produces a sparse representation of the counts\n",
    "We then fit the model using our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer() \n",
    "x_train_counts = cv.fit_transform(X_train.values) # fit_transform to counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train_counts) # scipy.sparse.csr.csr_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_transformer = TfidfTransformer(use_idf=False).fit(x_train_counts) # term frequency inverse document frequency matrix\n",
    "# I think this is a different way of transforming our data to counts, instead of just using 'transform'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform test values as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_counts = cv.transform(X_test.values) # transform test data as well (but we don't need to train it since its test data!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train_counts, Y_train) # fit the model on the training data word counts and training data lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Making the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = mnb.predict(x_test_counts) # make our y predictions (labels) on the comment test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "-1.0\n",
      "1.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "for i in predicted_labels[:10]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(predicted_labels).groupby(['-1.0','0.0','1.0']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well did we do?? (AKA accuracy metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(Y_test, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.5949 % accuracy for the model!\n"
     ]
    }
   ],
   "source": [
    "print('We obtained ', round(acc, 4), '% accuracy for the model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(predicted_labels == Y_test)  # same scoring method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.59      0.46      0.52        83\n",
      "        0.0       0.57      0.47      0.51        91\n",
      "        1.0       0.61      0.82      0.70       100\n",
      "\n",
      "avg / total       0.59      0.59      0.58       274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Here is the Classification Report: \\n')\n",
    "print(metrics.classification_report(Y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[38, 19, 26],\n",
       "       [22, 43, 26],\n",
       "       [ 4, 14, 82]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Here is the Confusion Matrix: \\n')\n",
    "metrics.confusion_matrix(Y_test, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next: SVM Classifier, TF-IDF transformations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', svm.SVC())\n",
    "                   ])\n",
    "svm_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36496350364963503"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_predicted = svm_clf.predict(X_test)\n",
    "np.mean(svm_predicted == Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                          alpha=1e-3, random_state=42,\n",
    "                                          max_iter=5, tol=None))])\n",
    "\n",
    "SGD_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62408759124087587"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_predicted = SGD_clf.predict(X_test)\n",
    "np.mean(SGD_predicted == Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network - Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SelectKBest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-ba2742dfce31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m NN_clf = Pipeline([('vect', CountVectorizer()),\n\u001b[1;32m      2\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                             \u001b[0;34m(\u001b[0m\u001b[0;34m'chi2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                             ('clf', MLPClassifier(\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SelectKBest' is not defined"
     ]
    }
   ],
   "source": [
    "NN_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('chi2', SelectKBest(chi2, k = 'all')),\n",
    "                            ('clf', MLPClassifier(\n",
    "                                    hidden_layer_sizes=(100,), \n",
    "                                    max_iter=10, \n",
    "                                    alpha=1e-4,\n",
    "                                    solver='sgd', \n",
    "                                    verbose=10, \n",
    "                                    tol=1e-4, \n",
    "                                    random_state=1,\n",
    "                                    learning_rate_init=.1)),\n",
    "                            ])\n",
    "\n",
    "NN_clf.fit(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
